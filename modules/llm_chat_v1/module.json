{
  "id": "llm_chat_v1",
  "name": "LLM Chat",
  "version": "2.0.0",
  "description": "Self-contained LLM chat interface. Manages conversation history, sessions, and provider configuration in-module. Host calls only for actual LLM API requests.",
  "minCryftteeVersion": "0.4.0",
  "selfContained": true,
  "hostCallsRequired": [
    "llm_request"
  ],
  "capabilities": [
    "send",
    "receiveResponse",
    "getHistory",
    "clearHistory",
    "newSession",
    "listSessions",
    "switchSession",
    "deleteSession",
    "setSystemPrompt",
    "configureProvider",
    "status"
  ],
  "moduleType": "llm",
  "hasGui": true,
  "guiPath": "gui",
  "abi": {
    "schemaVersion": "2.0.0",
    "entrypoint": "invoke",
    "memoryExports": ["alloc", "dealloc", "get_output_ptr"]
  },
  "providers": [
    {"name": "openai", "models": ["gpt-4", "gpt-3.5-turbo"]},
    {"name": "anthropic", "models": ["claude-3-opus", "claude-3-sonnet"]},
    {"name": "local", "models": ["llama", "mistral"]}
  ],
  "build": {
    "toolchain": "rust-1.80.0+wasm32-unknown-unknown",
    "dependencies": "none"
  }
}
